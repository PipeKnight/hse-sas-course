{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> У нас есть только 3 известых столбца, поэтому остальные из трейна перед обучением удалим, так как мы не сможем получить ответы по тем колонкам. Но из них мы можем попробовать выделить некоторые признаки и добавить в будущем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Начнём с изучения датасета для трейна с известным спросом </h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.rename(columns={\"Unnamed: 0\": \"id\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = df[df.demand.isna()].copy()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.product_rk == 40370) & (df.store_location_rk == 317)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим на цену, скорее всего, возьмём среднее значение для датасета с тестом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = df.groupby(by=[\"product_rk\"])[\"PRICE_REGULAR\"].describe().reset_index()\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_test = df_test.groupby(by=[\"product_rk\"])[\"PRICE_REGULAR\"].describe().reset_index()\n",
    "df_prices_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict = df_prices.set_index([\"product_rk\"])[\"mean\"]\n",
    "print(price_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict_test = df_prices_test.set_index([\"product_rk\"])[\"mean\"]\n",
    "print(price_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.agg(\n",
    "    [\n",
    "        \"nunique\",\n",
    "        (lambda x: x.nunique() / len(x) * 100),\n",
    "        (lambda x: x.isna().sum()),\n",
    "        (lambda x: x.isna().sum() / len(x) * 100),\n",
    "        (lambda x: x.isin([0]).sum()),\n",
    "        (lambda x: x.isin([0]).sum() / len(x) * 100),\n",
    "    ]\n",
    ").transpose()\n",
    "\n",
    "df_agg.columns = [\n",
    "    \"Unique\",\n",
    "    \"Percentage of unique\",\n",
    "    \"NaNs\",\n",
    "    \"Percentage of NaNs\",\n",
    "    \"Null values\",\n",
    "    \"Percentage of nulls\",\n",
    "]\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_test.agg(\n",
    "    [\n",
    "        \"nunique\",\n",
    "        (lambda x: x.nunique() / len(x) * 100),\n",
    "        (lambda x: x.isna().sum()),\n",
    "        (lambda x: x.isna().sum() / len(x) * 100),\n",
    "        (lambda x: x.isin([0]).sum()),\n",
    "        (lambda x: x.isin([0]).sum() / len(x) * 100),\n",
    "    ]\n",
    ").transpose()\n",
    "\n",
    "df_agg.columns = [\n",
    "    \"Unique\",\n",
    "    \"Percentage of unique\",\n",
    "    \"NaNs\",\n",
    "    \"Percentage of NaNs\",\n",
    "    \"Null values\",\n",
    "    \"Percentage of nulls\",\n",
    "]\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не нужен столбец PROMO2_FLAG, NUM_CONSULTANT - у всех единое значние. Пропущенные флаги заполним наиболее популярным значением, а для числовых признаков воспользуемся заполнением средним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.demand.notna()]\n",
    "df = df.drop(columns=[\"PROMO2_FLAG\", \"NUM_CONSULTANT\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=[\"PROMO2_FLAG\", \"NUM_CONSULTANT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.store_location_rk != 309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PROMO1_FLAG = df.PROMO1_FLAG.fillna(0)\n",
    "df.AUTORIZATION_FLAG = df.AUTORIZATION_FLAG.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PRICE_REGULAR = df.PRICE_REGULAR.fillna(df.PRICE_REGULAR.mean())\n",
    "df.PRICE_AFTER_DISC = df.PRICE_AFTER_DISC.fillna(df.PRICE_AFTER_DISC.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.PRICE_REGULAR = df_test.PRICE_REGULAR.fillna(df_test.PRICE_REGULAR.mean())\n",
    "df_test.PRICE_AFTER_DISC = df_test.PRICE_AFTER_DISC.fillna(df_test.PRICE_AFTER_DISC.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Будем предсказывать логарифм целевой величины (спроса), чтобы все числа находились на приблизительно одинаковом интервале."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(np.log1p(df.demand.values), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Изучим подбронее датасет с локациями магазинов </h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores = pd.read_csv(\"STORE_LOCATION.csv\", delimiter=\";\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_stores.agg(\n",
    "    [\n",
    "        \"nunique\",\n",
    "        (lambda x: x.nunique() / len(x) * 100),\n",
    "        (lambda x: x.isna().sum()),\n",
    "        (lambda x: x.isna().sum() / len(x) * 100),\n",
    "        (lambda x: x.isin([0]).sum()),\n",
    "        (lambda x: x.isin([0]).sum() / len(x) * 100),\n",
    "    ]\n",
    ").transpose()\n",
    "\n",
    "df_agg.columns = [\n",
    "    \"Unique\",\n",
    "    \"Percentage of unique\",\n",
    "    \"NaNs\",\n",
    "    \"Percentage of NaNs\",\n",
    "    \"Null values\",\n",
    "    \"Percentage of nulls\",\n",
    "]\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Колонки __[ STORE_LOCATION_ATTRIB17_hashing - STORE_LOCATION_ATTRIB21_hashing ]__ и __[STORE_LOCATION_LVL_RK1, STORE_CLOSURE_DTTM, STORE_LOCATION_ADK_hashing]__ не нужны, у всех одинаковое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores = df_stores.drop(\n",
    "    columns=[\n",
    "        \"STORE_LOCATION_ATTRIB17_hashing\",\n",
    "        \"STORE_LOCATION_ATTRIB18_hashing\",\n",
    "        \"STORE_LOCATION_ATTRIB19_hashing\",\n",
    "        \"STORE_LOCATION_ATTRIB20_hashing\",\n",
    "        \"STORE_LOCATION_ATTRIB21_hashing\",\n",
    "        \"STORE_LOCATION_LVL_RK1\",\n",
    "        \"STORE_CLOSURE_DTTM\",\n",
    "        \"STORE_LOCATION_ADK_hashing\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Объединим датасеты теперь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.set_index(\"store_location_rk\").join(df_stores.set_index(\"STORE_LOCATION_RK\"), how='inner').reset_index()\n",
    "df_model_test = df_test.set_index(\"store_location_rk\").join(df_stores.set_index(\"STORE_LOCATION_RK\"), how='inner').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"period_start_dt\"] = pd.to_datetime(df_model[\"period_start_dt\"])\n",
    "df_model_test[\"period_start_dt\"] = pd.to_datetime(df_model_test[\"period_start_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"day\"] = df_model[\"period_start_dt\"].dt.day\n",
    "df_model[\"month\"] = df_model[\"period_start_dt\"].dt.month\n",
    "df_model[\"day_year\"] = df_model[\"period_start_dt\"].dt.dayofyear\n",
    "df_model[\"weekday\"] = df_model[\"period_start_dt\"].dt.weekday\n",
    "\n",
    "df_model_test[\"day\"] = df_model_test[\"period_start_dt\"].dt.day\n",
    "df_model_test[\"month\"] = df_model_test[\"period_start_dt\"].dt.month\n",
    "df_model_test[\"day_year\"] = df_model_test[\"period_start_dt\"].dt.dayofyear\n",
    "df_model_test[\"weekday\"] = df_model_test[\"period_start_dt\"].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Нашли ещё один константный признак, удалим его и один старый признак (дату), который больше не нужен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test.STORE_OPEN_DTTM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.STORE_OPEN_DTTM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(columns=[\"STORE_OPEN_DTTM\"])\n",
    "df_model_test = df_model_test.drop(columns=[\"STORE_OPEN_DTTM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(columns=[\"period_start_dt\"])\n",
    "df_model_test = df_model_test.drop(columns=[\"period_start_dt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Применим логарифм к таргету:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"demand\"] = np.log1p(df_model[\"demand\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выделим строки, где спрос был равен 0-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"flag_zero\"] = np.where(df_model[\"demand\"] <= 0.75, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expm1(2.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.flag_zero.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Отдельно выделим строки флагом, где спрос был больше 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"flag_much\"] = np.where(df_model[\"demand\"] > 2.75, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.flag_much.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Теперь получим таблицу среднего спроса по месяцам и товарам без нулевых товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (\n",
    "    df_model[df_model.flag_zero == 0]\n",
    "    .groupby([\"product_rk\", \"month\"])[\"demand\"]\n",
    "    .describe()[[\"mean\", \"50%\"]]\n",
    ")\n",
    "temp = temp.reset_index()\n",
    "temp[[\"mean\", \"50%\"]] = np.expm1(temp[[\"mean\", \"50%\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict = temp.set_index([\"product_rk\", \"month\"])[\"mean\"].to_dict()\n",
    "half_dict = temp.set_index([\"product_rk\", \"month\"])[\"50%\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"50%\"] = pd.Series(list(zip(df_model.product_rk, df_model.month))).map(half_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"mean_demand\"] = pd.Series(list(zip(df_model.product_rk, df_model.month))).map(mean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"50%\"] = pd.Series(list(zip(df_model_test.product_rk, df_model_test.month))).map(half_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"mean_demand\"] = pd.Series(\n",
    "    list(zip(df_model_test.product_rk, df_model_test.month))\n",
    ").map(mean_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Разделим выборку </h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_model[\"flag_zero\"]\n",
    "X = df_model.drop(columns=[\"flag_zero\", \"flag_much\", \"demand\", \"id\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=808, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df_model.columns)\n",
    "features = features[\n",
    "    ~np.isin(\n",
    "        features,\n",
    "        [\"flag_zero\", \"demand\", \"flag_much\", \"id\"],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выведим все признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = features[\n",
    "    ~np.isin(\n",
    "        features,\n",
    "        [\"day\", \"day_year\", \"demand\", \"50%\", \"mean_demand\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"day\", \"day_year\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_smape(A, F):\n",
    "    A = np.expm1(A)\n",
    "    F = np.expm1(F)\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "smape = make_scorer(my_smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_flags = xgb.XGBClassifier(n_estimators=120, learning_rate=0.22, max_depth=10, \n",
    "                              reg_lambda=1, eval_metric=\"aucpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"scaling\", StandardScaler(), numeric),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"ohe_and_scaling\", column_transformer),\n",
    "        (\n",
    "            \"GBRegressor\",\n",
    "            xgb_flags,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделаем метрику accuracy и запустим кросс-валидацию, чтобы посмотреть качество классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_accuracy_score = make_scorer(f1_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline\n",
    "print(cross_val_score(model, X_train, y_train, cv=7, scoring=my_accuracy_score).sum() / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_temp = model.predict(X_test)\n",
    "accuracy_score(y_test, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделаем модель для классификации товаров с 0 спросом и обычным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_flags = flags_model.predict(df_model_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"flag_zero\"] = y_preds_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"flag_zero\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.flag_zero.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Отношение величин получилось немного другим, но попробуем пока обучить такие модели. Выделим отдельно часть датасета, где спрос был ненулевой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.flag_much.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_model[\"flag_much\"]\n",
    "X = df_model.drop(columns=[\"flag_zero\", \"flag_much\", \"demand\", \"id\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=808, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(X.columns)\n",
    "features = features[\n",
    "    ~np.isin(\n",
    "        features,\n",
    "        [\"flag_zero\", \"demand\", \"flag_much\", \"50%\", \"mean_demand\", \"id\"],\n",
    "    )\n",
    "]\n",
    "\n",
    "categorical = features[\n",
    "    ~np.isin(\n",
    "        features,\n",
    "        [\"demand\", \"50%\", \"mean_demand\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"],\n",
    "    )\n",
    "]\n",
    "\n",
    "numeric = [\"day\", \"day_year\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_flags1 = xgb.XGBClassifier(n_estimators=150, learning_rate=0.21, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"scaling\", StandardScaler(), numeric),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline1 = Pipeline(\n",
    "    steps=[\n",
    "        (\"ohe_and_scaling\", column_transformer),\n",
    "        (\n",
    "            \"GBRegressor\",\n",
    "            xgb_flags1,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline1\n",
    "print(cross_val_score(model, X_train[features], y_train, cv=5, scoring=my_accuracy_score).sum() / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train[features], y_train)\n",
    "y_temp = model.predict(X_test[features])\n",
    "accuracy_score(y_test, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags1_model = pipeline1.fit(X_train[features], y_train)\n",
    "y_preds_flags1 = flags1_model.predict(df_model_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"flag_much\"] = y_preds_flags1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test[\"flag_much\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Теперь обучим модель на обычных значениях, то есть на ненулевых и не на выбросах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_one = df_model[(df_model.flag_zero == 0) & (df_model.flag_much == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_model_one[\"demand\"]\n",
    "X = df_model_one.drop(columns=[\"flag_zero\", \"flag_much\", \"demand\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'eval_metric': 'mae', 'eta': 0.21, 'n_estimators': 180, 'max_depth': 7}\n",
    "xgb_cool = xgb.XGBRegressor(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'eval_metric': 'mae', 'eta': 0.23, 'n_estimators': 130, 'max_depth': 6}\n",
    "xgb_cool2 = xgb.XGBRegressor(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = Ridge(alpha = 0.2, tol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_cool = RandomForestRegressor(n_estimators=10, max_depth=7, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest3 = RandomForestRegressor(n_estimators=12, max_depth=6, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest4 = RandomForestRegressor(n_estimators=16, max_depth=8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(X.columns)\n",
    "\n",
    "categorical = features[\n",
    "    ~np.isin(\n",
    "        features,\n",
    "        [\"demand\", \"50%\", \"mean_demand\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"],\n",
    "    )\n",
    "]\n",
    "\n",
    "numeric = [\"day\", \"day_year\", \"PRICE_REGULAR\", \"PRICE_AFTER_DISC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', forest_cool),\n",
    "    ('svr', xgb_cool),\n",
    "    ('ugabuga', linreg),\n",
    "    ('linrega', forest4)\n",
    "]\n",
    "\n",
    "reg2 = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RidgeCV(cv=None, scoring=\"neg_root_mean_squared_error\", alphas=np.logspace(-2, 4, 100))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"scaling\", StandardScaler(), numeric),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"ohe_and_scaling\", column_transformer),\n",
    "        (\n",
    "            \"forest\",\n",
    "            reg2,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline\n",
    "#print(\"SMAPE CV:\")\n",
    "#print(cross_val_score(model, X, y, cv=5, scoring=smape, n_jobs=-1).sum() / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X[features], y)\n",
    "y_pred_global = model.predict(df_model_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_global = np.expm1(y_pred_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_oracle_predict = df_model_test[[\"id\", \"demand\", \"flag_zero\", \"flag_much\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_oracle_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_oracle_predict.demand = y_pred_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_oracle_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"sample_submission.csv\", index_col=None)\n",
    "temp = temp.id.values\n",
    "df_temp = df_global_oracle_predict[np.isin(\n",
    "        df_global_oracle_predict.id,\n",
    "        temp,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(columns=[\"flag_zero\", \"flag_much\"])\n",
    "df_temp = df_temp.rename(columns={'demand': 'predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_temp.predicted[df_temp.predicted < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"out3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
